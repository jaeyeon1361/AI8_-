{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"22_05_26_day10_seq2seq.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP5ov/wlsgLLv0YRYt2vxHg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# seq2seq 모델"],"metadata":{"id":"q0MlIIp8wfZI"}},{"cell_type":"markdown","source":["![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"],"metadata":{"id":"BYf-_1t1wiII"}},{"cell_type":"markdown","source":["## Encoder 구현"],"metadata":{"id":"SUO9UmWfwk2Q"}},{"cell_type":"markdown","source":["![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-6.max-800x600.jpg)"],"metadata":{"id":"lCPSBCPdwnNf"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"aT83VDAopzxr","executionInfo":{"status":"ok","timestamp":1653524862069,"user_tz":-540,"elapsed":3854,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["class Encoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, enc_units):\n","        super(Encoder, self).__init__()\n","        self.embedding = tf.keras.layers.# None( 변수 1, 변수 2) # 나는 밥을 먹었어\n","        self.lstm = tf.keras.layers.# None ( 변수 3 )\n","    \n","    def call(self, x):\n","        print(\"입력 shape :\", x.shape) # sample input // 춤 추는 소시지 \n","\n","        x = None\n","        print(\"Embedding Layer를 거친 shape :\", x.shape)\n","\n","        output = None\n","        print(\"LSTM shape의 output shape :\", output.shape)\n","        \n","        return output"],"metadata":{"id":"slWrhuY1wuw5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 30000\n","emb_size = 256\n","lstm_size = 512\n","batch_size = 1\n","sample_seq_len = 3\n","\n","print(\"Vocab Size : {0}\".format(vocab_size))\n","print(\"Embedding Size : {0}\".format(emb_size))\n","print(\"LSTM Size : {0}\".format(lstm_size))\n","print(\"Batch_size : {0}\".format(batch_size))\n","print(\"Sample Sequence Length : {0}\".format(sample_seq_len))"],"metadata":{"id":"2mgOnbTXxCMX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["encoder = Encoder(None, None, None) #vocab_size, embedding_dim, enc_units):\n","sample_input = tf.zeros((None, None)) # 춤 추는 소시지\n","\n","sample_output = encoder(None)"],"metadata":{"id":"T0nOgRrexIzw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Decoder 구현"],"metadata":{"id":"YaCFAU30xPMf"}},{"cell_type":"markdown","source":["![](https://aiffelstaticprd.blob.core.windows.net/media/images/GN-4-L-7.max-800x600.jpg)"],"metadata":{"id":"dFRBUyamxRYf"}},{"cell_type":"code","source":["class Decoder(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, dec_units):\n","        super(Decoder, self).__init__()\n","        self.embedding = tf.keras.layers. # None (변수 1, 변수 2)\n","        self.lstm = tf.keras.layers. # None (변수 3, return_sequences=True) ####\n","        self.fc = tf.keras.layers.# None(변수 4)\n","        self.softmax = tf.keras.layers.# None (변수 5)\n","\n","    def call(self, x, context_v):\n","        print(\"입력 shape : \", x.shape)\n","\n","        x = None\n","        print(\"Embedding layer를 거친 shape\", x.shape)\n","\n","        context_v = tf.repeat(tf.expand_dims(context_v, axis=1), repeats=x.shape[1], axis=1)\n","        x = tf.concat(# [변수 1, 변수 2], axis = -1)\n","        print('Context Vector가 더해진 shape : ', x.shape)\n","\n","        x = None\n","        print(\"LSTM layer의 output layer : \", x.shape)\n","\n","        output = None\n","        print(\"Decoder의 최종 ouput layer : \", output.shape)\n","\n","        output = None\n","\n","        return output"],"metadata":{"id":"QNPaQgSVxNvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocab_size = 30000\n","emb_size = 256\n","lstm_size = 512\n","batch_size = 1\n","sample_seq_len = 3\n","\n","print(\"Vocab Size : {0}\".format(vocab_size))\n","print(\"Embedding Size : {0}\".format(emb_size))\n","print(\"LSTM Size : {0}\".format(lstm_size))\n","print(\"Batch_size : {0}\".format(batch_size))\n","print(\"Sample Sequence Length : {0}\".format(sample_seq_len))"],"metadata":{"id":"zmLtmubHxzyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(None, None, None)\n","sample_input = tf.zeros((None, None)) # 춤 추는 소시지\n","\n","sample_output = decoder(None, None)"],"metadata":{"id":"ZwalJJzKx0W-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Attention"],"metadata":{"id":"I2rWe11Hyake"}},{"cell_type":"markdown","source":["- Bahdanau Attention\n","$$ Score_{alignment} = W * tanh(W_{decoder} * H_{decoder} + W_{encoder} * H_{encoder}) $$"],"metadata":{"id":"HVVLgiLHycqX"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"W2CJ2qliyaxn","executionInfo":{"status":"ok","timestamp":1653525315378,"user_tz":-540,"elapsed":270,"user":{"displayName":"백혜림","userId":"01884416935170274848"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class BahdanauAttention(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super(BahdanauAttention, self).__init__()\n","        self.w_decoder = None\n","        self.w_encoder = None\n","        self.w_combine = None\n","    \n","    def call(self, h_encoder, h_decoder):\n","        print(\"[H_encoder] shape : \", h_encoder.shape)\n","\n","        h_encoder = None\n","        print(\"[w_encoder x h_encoder] shape : \", h_encoder.shape)\n","\n","        print(\"\\n[H_decoder shape :\", h_decoder.shape)\n","        h_decoder = tf.expand_dims(h_decoder, 1)\n","        h_decoder = None\n","\n","        print(\"[w_encoder x h_decoder] shape :\", h_decoder.shape)\n","\n","        score = None\n","        print(\"[score alinment] shape :\", score.shape)\n","\n","        attention_weights = None\n","        print(\"\\n최종 weight : \\n\", attention_weights.numpy())\n","\n","        context_vector = None\n","        context_vector = tf.reduce_sum(context_vector, axis = 1)\n","\n","        return context_vector, attention_weights"],"metadata":{"id":"9csARr_vyftu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w_size = 100\n","print(\"hidden state {0}차원으로 Mapping \\n\".format(w_size))\n","\n","attention = BahdanauAttention(w_size)\n","\n","enc_state = tf.random.uniform((1, 10, 512))\n","dec_state = tf.random.uniform((1, 512))\n","\n","_ = attention(enc_state, dec_state)"],"metadata":{"id":"TdSyZrAnzUQk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["![](https://aiffelstaticprd.blob.core.windows.net/media/original_images/GN-4-L-9.jpg)"],"metadata":{"id":"E-Fw7WBDzX18"}},{"cell_type":"markdown","source":["# Loung Attention"],"metadata":{"id":"eSfQTfeGzbLc"}},{"cell_type":"markdown","source":["$$ Score(H_{target},H_{source}) = H_{target}^T * W_{combine} * H_{source}$$"],"metadata":{"id":"gu8BHyqmzc2O"}},{"cell_type":"code","source":["class LuongAttention(tf.keras.layers.Layer):\n","    def __init__(self, units):\n","        super(LuongAttention, self).__init__()\n","        self.w_combine = None\n","\n","    def call(self, h_encoder, h_decoder):\n","        print(\"[h_encoder] shape : \", h_encoder.shape)\n","\n","        wh = None\n","        print(\"[W_encoder x h_encoder] shape :\", wh.shape)\n","\n","        h_decoder = tf.expand_dims(h_decoder, 1)\n","        alignment = None\n","        print(\"[Score alignment] shape : \", alignment.shape)\n","\n","        attention_weights = None\n","        print(\"\\n 최종 weight : \\n\", attention_weights.numpy())\n","\n","        attention_weights = tf.squeeze(None, axis= -1)\n","        context_vector = None\n","\n","        return context_vector, attention_weights"],"metadata":{"id":"UO1Xn8V5zbXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["emb_dim = 512\n","attention = LuongAttention(emb_size)\n","\n","enc_state = tf.random.uniform((1, 10, emb_size))\n","dec_state = tf.random.uniform((1, emb_size))\n","\n","_ = attention(enc_state, dec_state)"],"metadata":{"id":"qd-KxPyKzo5l"},"execution_count":null,"outputs":[]}]}