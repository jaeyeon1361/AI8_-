{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff1b040",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1973dd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.503637\n",
      "tile roof\n",
      "tile roof(50.36%)\n"
     ]
    }
   ],
   "source": [
    "file_name = '../goolgenet_fig/img_theater02_03.jpg'\n",
    "\n",
    "img = cv2.imread(file_name)\n",
    "\n",
    "if img is None : \n",
    "    print('img read failed')\n",
    "    sys.exit()\n",
    "\n",
    "# caffe model import \n",
    "model = '../googlenet/bvlc_googlenet.caffemodel'\n",
    "config = '../googlenet/deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "classNames = []\n",
    "with open('../googlenet/classification_classes_ILSVRC2012.txt', 'rt') as f : # 위 텍스트를 읽어줌\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')  \n",
    "\n",
    "## DL\n",
    "# blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n",
    "blob = cv2.dnn.blobFromImage(img, 1,(224,224), (104, 117, 123),\n",
    "                            swapRB = False)\n",
    "\n",
    "net.setInput(blob)\n",
    "prob = net.forward()\n",
    "\n",
    "out = prob.flatten() # 벡터를 없애줌\n",
    "classld = np.argmax(out) # 배열 중에서 제일 높은 수치의 모델을 알려달라\n",
    "#print(classld)\n",
    "confidence = out[classld]\n",
    "print(confidence) # 해당 배열의 수치를 나타내줌\n",
    "class_text = classNames[classld]\n",
    "print(class_text)\n",
    "\n",
    "\n",
    "text = f'{class_text}({confidence*100:.2f}%)' # 보기좋게 % 지로 표현\n",
    "print(text)\n",
    "\n",
    "cv2.putText(img, text, (10, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2, cv2.LINE_AA) # 사진안에 text\n",
    "\n",
    "#print(prob[0,:10])\n",
    "                                            \n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2e2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../face/KakaoTalk_20220823_164939646_01.jpg')\n",
    "\n",
    "if img is None:\n",
    "    print('image read failed')\n",
    "    sys.exit()\n",
    "    \n",
    "model = '../googlenet/opencv_face_detector_uint8.pb'\n",
    "config = '../googlenet/opencv_face_detector.pbtxt.txt'\n",
    "\n",
    "face_net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if face_net.empty():\n",
    "    print('Net open failed')\n",
    "    sys.exit()\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (300, 300), (104, 177, 123),\n",
    "                            swapRB=False)\n",
    "\n",
    "face_net.setInput(blob)\n",
    "out = face_net.forward()\n",
    "\n",
    "detect = out[0, 0, :, :]\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for i in range(detect.shape[0]):\n",
    "    confidence = detect[i, 2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        # out matrix에서 x1, y1, x2, y2 값이 0 ~1로 normalize 되어 있음\n",
    "        \n",
    "        x1 = int(detect[i, 3]*w)\n",
    "        y1 = int(detect[i, 4]*h)\n",
    "        x2 = int(detect[i, 5]*w)\n",
    "        y2 = int(detect[i, 6]*h)\n",
    "        \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2),\n",
    "                     (0, 0, 255))\n",
    "        \n",
    "        text='Face:{}%'.format(round(confidence*100,2))\n",
    "        cv2.putText(img, text, (x1, y1-1), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                   0.8, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4670c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=cv2.imread('./fig/face.png',cv2.IMREAD_REDUCED_COLOR_2)\n",
    "model='../googlenet/opencv_face_detector_uint8.pb'\n",
    "config='../googlenet/opencv_face_detector.pbtxt.txt'\n",
    "\n",
    "face_net=cv2.dnn.readNet(model,config)\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('video open failed')\n",
    "    sys.exit()\n",
    "\n",
    "# w=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# h=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "# fps=int(cap.get(cv2.CAP_PROP_FPS)*0.8)\n",
    "# foucc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "    \n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        print('frame read failed')\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123),swapRB=False)\n",
    "    face_net.setInput(blob)\n",
    "    out=face_net.forward()\n",
    "\n",
    "    detect=out[0,0,:,:]\n",
    "\n",
    "    h,w=frame.shape[:2]\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence=detect[i,2]\n",
    "        if confidence > 0.5:\n",
    "            x1=int(detect[i,3]*w)\n",
    "            y1=int(detect[i,4]*h)\n",
    "            x2=int(detect[i,5]*w)\n",
    "            y2=int(detect[i,6]*h)\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,125,255),2)\n",
    "            text='Face:{}%'.format(round(confidence*100,2))\n",
    "            cv2.putText(frame,text,(x1,y1-2),cv2.FONT_HERSHEY_COMPLEX,1,(0,125,255),1,cv2.LINE_AA)\n",
    "#             cv2.flip(text_flip)\n",
    "#     edge=cv2.Canny(frame,50,150)\n",
    "    flip=cv2.flip(frame,1)\n",
    "#    cv2.imshow('image',frame)\n",
    "#     cv2.imshow('edge',edge)\n",
    "#    cv2.imshow('flip',flip)\n",
    "    \n",
    "#     out.write('outvideo',flip)\n",
    "    \n",
    "    if cv2.waitKey(20)==27:\n",
    "        break\n",
    "# out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "        \n",
    "# print(detect.shape)\n",
    "# cv2.imshow('image',img)\n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06bd4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 강사님이 내준거\n",
    "img_list = os.listdir('../goolgenet_fig/')\n",
    "\n",
    "file_name = []\n",
    "for i in img_list:\n",
    "    img_path = '../goolgenet_fig/'+i\n",
    "    file_name.append(img_path)\n",
    "\n",
    "model = '../googlenet/bvlc_googlenet.caffemodel'\n",
    "config = '../googlenet/deploy.prototxt'\n",
    "\n",
    "net = cv2.dnn.readNet(model,config)\n",
    "\n",
    "classNames = []\n",
    "with open('../googlenet/classification_classes_ILSVRC2012.txt','rt') as f:\n",
    "    classNames = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "\n",
    "idx=0\n",
    "while True:\n",
    "    img = cv2.imread(file_name[idx])\n",
    "\n",
    "    if img is None:\n",
    "        print('img read err')\n",
    "        sys.exit()\n",
    "    img=cv2.resize(img,(500,500))\n",
    "    blob = cv2.dnn.blobFromImage(img,1,(224,224),(104,117,123),\n",
    "                                swapRB=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    prob = net.forward()\n",
    "\n",
    "    out = prob.flatten()\n",
    "    classid =np.argmax(out)\n",
    "    confidence = out[classid]\n",
    "    class_text = classNames[classid]\n",
    "    text = f'{class_text} ({confidence*100:.2f}%)'\n",
    "    cv2.putText(img,text,(10,30),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('image',img)\n",
    "\n",
    "    if cv2.waitKey(3000)==27:\n",
    "        break\n",
    "    idx+=1\n",
    "    if idx>=len(file_name):\n",
    "        idx=0\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ebd4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영상 얼굴인식\n",
    "model='../googlenet/opencv_face_detector_uint8.pb'\n",
    "config='../googlenet/opencv_face_detector.pbtxt.txt'\n",
    "\n",
    "face_net=cv2.dnn.readNet(model,config)\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('video open failed')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        print('frame read failed')\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123),swapRB=False)\n",
    "    face_net.setInput(blob)\n",
    "    out=face_net.forward()\n",
    "\n",
    "    detect=out[0,0,:,:]\n",
    "\n",
    "    h,w=frame.shape[:2]\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence=detect[i,2]\n",
    "        if confidence > 0.5:\n",
    "            x1=int(detect[i,3]*w)\n",
    "            y1=int(detect[i,4]*h)\n",
    "            x2=int(detect[i,5]*w)\n",
    "            y2=int(detect[i,6]*h)\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,125,255),2)\n",
    "            text='Face:{}%'.format(round(confidence*100,2))\n",
    "            cv2.putText(frame,text,(x1,y1-2),cv2.FONT_HERSHEY_COMPLEX,1,(0,125,255),1,cv2.LINE_AA)\n",
    "#             cv2.flip(text_flip)\n",
    "#     edge=cv2.Canny(frame,50,150)\n",
    "    flip=cv2.flip(frame,1)\n",
    "    cv2.imshow('image',frame)\n",
    "#    cv2.imshow('edge',edge)\n",
    "#    cv2.imshow('flip',flip)\n",
    "    \n",
    "    if cv2.waitKey(20)==27:\n",
    "        break\n",
    "# out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b969d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
