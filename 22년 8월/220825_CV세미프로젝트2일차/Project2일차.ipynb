{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beeea3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import mediapipe as mp\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bd8e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../pubg/456(수정).m4v')\n",
    "\n",
    "\n",
    "if cap is None : \n",
    "    print('Video read failed')\n",
    "    sys.exit()\n",
    "                    \n",
    "    \n",
    "while True : \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False :\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(10) == 27 :\n",
    "        break\n",
    "        \n",
    "    resize_frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('video', resize_frame)   \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1464c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2208251639 안됌\n",
    "cap = cv2.VideoCapture('../pubg/456(수정).m4v')\n",
    "\n",
    "\n",
    "if cap is None : \n",
    "    print('Video read failed')\n",
    "    sys.exit()\n",
    "                    \n",
    "    \n",
    "while True : \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False :\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(10) == 27 :\n",
    "        break\n",
    "        \n",
    "    resize_frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('video', resize_frame)   \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00477ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../pubg/789.mp4\")\n",
    "\n",
    "# 배경 제거 객체 생성\n",
    "\n",
    "fgbg = cv2.bgsegm.createBackgroundSubtractorMOG()\n",
    "\n",
    " \n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 배경 제거 마스크 계산\n",
    "\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame', frame)\n",
    "   # cv2.imshow('bg', fgmask)\n",
    "    resize_frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    if cv2.waitKey(1) & 0xff == 27:\n",
    "\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feeabd4",
   "metadata": {},
   "source": [
    " BackgroundSubtractorMOG2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecec8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 매우잘됌 2208251700\n",
    "\n",
    "cap = cv2.VideoCapture('../pubg/123.mp4')\n",
    "\n",
    "# 옵션 설명 http://layer0.authentise.com/segment-background-using-computer-vision.html\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=100, detectShadows=0)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    width = frame.shape[1]\n",
    "    height = frame.shape[0]\n",
    "    frame = cv2.resize(frame, (int(width/3), int(height/3)))\n",
    "    fgmask = fgbg.apply(frame)\n",
    "\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(fgmask)\n",
    "\n",
    "\n",
    "    for index, centroid in enumerate(centroids):\n",
    "        if stats[index][0] == 0 and stats[index][1] == 0:\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid)):\n",
    "            continue\n",
    "\n",
    "\n",
    "        x, y, width, height, area = stats[index]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "        if area > 10:\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 0, 255))\n",
    "\n",
    "\n",
    "    cv2.imshow('mask',fgmask)\n",
    "    cv2.imshow('frame',frame)\n",
    "\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1971d6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"../pubg/456(수정).m4v\")\n",
    "\n",
    "# 옵션 설명 http://layer0.authentise.com/segment-background-using-computer-vision.html\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2(varThreshold=100)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(fgmask)\n",
    "\n",
    "\n",
    "    for index, centroid in enumerate(centroids):\n",
    "        if stats[index][0] == 0 and stats[index][1] == 0:\n",
    "            continue\n",
    "        if np.any(np.isnan(centroid)):\n",
    "            continue\n",
    "\n",
    "\n",
    "        x, y, width, height, area = stats[index]\n",
    "        centerX, centerY = int(centroid[0]), int(centroid[1])\n",
    "\n",
    "        if area > 5:\n",
    "            cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 0, 255))\n",
    "            re_frame = cv2.resize(frame, (1280, 960), interpolation=cv2.INTER_CUBIC)\n",
    "            cv2.imshow('video', re_frame)   \n",
    "\n",
    "\n",
    "    # cv2.imshow('mask',fgmask)\n",
    "\n",
    "    k = cv2.waitKey(50) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b07729",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('../pubg/789.mp4')\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_objectron = mp.solutions.objectron\n",
    "\n",
    "with mp_objectron.Objectron(static_image_mode=False,\n",
    "                            max_num_objects=5,\n",
    "                            min_detection_confidence=0.5,\n",
    "                            min_tracking_confidence=0.99,\n",
    "                            model_name='Shoe') as objectron:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"카메라를 찾을 수 없습니다.\")\n",
    "            break\n",
    "            \n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = objectron.process(image)\n",
    "        \n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.detected_objects:\n",
    "            for detected_object in results.detected_objects:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                  image, detected_object.landmarks_2d, mp_objectron.BOX_CONNECTIONS)\n",
    "                mp_drawing.draw_axis(image, detected_object.rotation,\n",
    "                                     detected_object.translation)\n",
    "\n",
    "if cap is None : \n",
    "    print('Video read failed')\n",
    "    sys.exit()\n",
    "                    \n",
    "    \n",
    "while True : \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == False :\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(10) == 27 :\n",
    "        break\n",
    "        \n",
    "    resize_frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    # cv2.imshow('video', resize_frame)   \n",
    "    cv2.imshow('MediaPipe Objectron', cv2.flip(image, 1))\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f5c980",
   "metadata": {},
   "outputs": [],
   "source": [
    "model='../googlenet/opencv_face_detector_uint8.pb'\n",
    "config='../googlenet/opencv_face_detector.pbtxt.txt'\n",
    "\n",
    "face_net=cv2.dnn.readNet(model,config)\n",
    "\n",
    "cap=cv2.VideoCapture('../pubg/456.mp4')\n",
    "if not cap.isOpened():\n",
    "    print('video open failed')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret,frame=cap.read()\n",
    "    if not ret:\n",
    "        print('frame read failed')\n",
    "        break\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123),swapRB=False)\n",
    "    face_net.setInput(blob)\n",
    "    out=face_net.forward()\n",
    "\n",
    "    detect=out[0,0,:,:]\n",
    "\n",
    "    h,w=frame.shape[:2]\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence=detect[i,2]\n",
    "        if confidence > 0.5:\n",
    "            x1=int(detect[i,3]*w)\n",
    "            y1=int(detect[i,4]*h)\n",
    "            x2=int(detect[i,5]*w)\n",
    "            y2=int(detect[i,6]*h)\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,125,255),2)\n",
    "\n",
    "    resize_frame = cv2.resize(frame, (1280, 720), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('image',resize_frame)\n",
    "    \n",
    "    if cv2.waitKey(20)==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87c39c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cap \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../pubg/789.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m body_cascade \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mCascadeClassifier(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../googlenet/haarcascade_fullbody.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m prev_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('../pubg/789.mp4')\n",
    "\n",
    "body_cascade = cv2.CascadeClassifier('../googlenet/haarcascade_fullbody.xml')\n",
    "\n",
    "prev_time = 0\n",
    "FPS = 10\n",
    "\n",
    "if cap is None : \n",
    "    print('Video read failed')\n",
    "    sys.exit()\n",
    "                    \n",
    "while True : \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    body = body_cascade.detectMultiScale(grayframe, 1.01, 10, minSize=(30, 30))\n",
    "    for (x,y,w,h) in body :         \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3, 4, 0)\n",
    "    \n",
    "    #cv2.imshow('body', frame)\n",
    "    \n",
    "    if ret == False :\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(10) == 27 :\n",
    "        break\n",
    "        \n",
    "    resize_frame = cv2.resize(frame, (960, 640), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('video', resize_frame)   \n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd775f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2208251624 \n",
    "cap = cv2.VideoCapture('../pubg/456(수정).m4v')\n",
    "\n",
    "fps =int(cap.get(cv2.CAP_PROP_FPS)*0.8)\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FPS, fps*0.8)\n",
    "\n",
    "body_cascade = cv2.CascadeClassifier('../googlenet/haarcascade_fullbody.xml')\n",
    "\n",
    "prev_time = 0\n",
    "FPS = 10\n",
    "\n",
    "if cap is None : \n",
    "    print('Video read failed')\n",
    "    sys.exit()\n",
    "                    \n",
    "while True : \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    body = body_cascade.detectMultiScale(grayframe, 1.01, 10, minSize=(30, 30))\n",
    "    for (x,y,w,h) in body :         \n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),3, 4, 0)\n",
    "    \n",
    "    #cv2.imshow('body', frame)\n",
    "    \n",
    "    if ret == False :\n",
    "        break\n",
    "    \n",
    "    if cv2.waitKey(10) == 27 :\n",
    "        break\n",
    "        \n",
    "    resize_frame = cv2.resize(frame, (960, 640), interpolation=cv2.INTER_CUBIC)\n",
    "    cv2.imshow('video', resize_frame)   \n",
    "    \n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2d5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2208251704\n",
    "cap = cv2.VideoCapture('../pubg/123.mp4')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "# 배경 제거 객체 생성 --- ①\n",
    "fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # 배경 제거 마스크 계산 --- ②\n",
    "    fgmask = fgbg.apply(frame)\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('bgsub',fgmask)\n",
    "    if cv2.waitKey(delay) & 0xff == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2208251714 내일해볼꺼!!!!!!!!!!\n",
    "## https://bkshin.tistory.com/entry/OpenCV-32-객체-추적을-위한-Tracking-API\n",
    "# 트랙커 객체 생성자 함수 리스트 ---①\n",
    "trackers = [cv2.TrackerBoosting_create,\n",
    "            cv2.TrackerMIL_create,\n",
    "            cv2.TrackerKCF_create,\n",
    "            cv2.TrackerTLD_create,\n",
    "            cv2.TrackerMedianFlow_create,\n",
    "            cv2.TrackerGOTURN_create, #버그로 오류 발생\n",
    "            cv2.TrackerCSRT_create,\n",
    "            cv2.TrackerMOSSE_create]\n",
    "trackerIdx = 0  # 트랙커 생성자 함수 선택 인덱스\n",
    "tracker = None\n",
    "isFirst = True\n",
    "\n",
    "video_src = 0 # 비디오 파일과 카메라 선택 ---②\n",
    "video_src = \"../img/highway.mp4\"\n",
    "cap = cv2.VideoCapture(video_src)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS) # 프레임 수 구하기\n",
    "delay = int(1000/fps)\n",
    "win_name = 'Tracking APIs'\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Cannot read video file')\n",
    "        break\n",
    "    img_draw = frame.copy()\n",
    "    if tracker is None: # 트랙커 생성 안된 경우\n",
    "        cv2.putText(img_draw, \"Press the Space to set ROI!!\", \\\n",
    "            (100,80), cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    else:\n",
    "        ok, bbox = tracker.update(frame)   # 새로운 프레임에서 추적 위치 찾기 ---③\n",
    "        (x,y,w,h) = bbox\n",
    "        if ok: # 추적 성공\n",
    "            cv2.rectangle(img_draw, (int(x), int(y)), (int(x + w), int(y + h)), \\\n",
    "                          (0,255,0), 2, 1)\n",
    "        else : # 추적 실패\n",
    "            cv2.putText(img_draw, \"Tracking fail.\", (100,80), \\\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.75,(0,0,255),2,cv2.LINE_AA)\n",
    "    trackerName = tracker.__class__.__name__\n",
    "    cv2.putText(img_draw, str(trackerIdx) + \":\"+trackerName , (100,20), \\\n",
    "                 cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0,255,0),2,cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow(win_name, img_draw)\n",
    "    key = cv2.waitKey(delay) & 0xff\n",
    "    # 스페이스 바 또는 비디오 파일 최초 실행 ---④\n",
    "    if key == ord(' ') or (video_src != 0 and isFirst): \n",
    "        isFirst = False\n",
    "        roi = cv2.selectROI(win_name, frame, False)  # 초기 객체 위치 설정\n",
    "        if roi[2] and roi[3]:         # 위치 설정 값 있는 경우\n",
    "            tracker = trackers[trackerIdx]()    #트랙커 객체 생성 ---⑤\n",
    "            isInit = tracker.init(frame, roi)\n",
    "    elif key in range(48, 56): # 0~7 숫자 입력   ---⑥\n",
    "        trackerIdx = key-48     # 선택한 숫자로 트랙커 인덱스 수정\n",
    "        if bbox is not None:\n",
    "            tracker = trackers[trackerIdx]() # 선택한 숫자의 트랙커 객체 생성 ---⑦\n",
    "            isInit = tracker.init(frame, bbox) # 이전 추적 위치로 추적 위치 초기화\n",
    "    elif key == 27 : \n",
    "        break\n",
    "else:\n",
    "    print( \"Could not open video\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb327535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 내일해볼꺼 222222\n",
    "## https://deep-learning-study.tistory.com/275\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture('camshift.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 초기 사각형 영역: (x, y, w, h)\n",
    "# ROI로 선택해도 되지만 강제로 입력함\n",
    "x, y, w, h = 135, 220, 100, 100\n",
    "rc = (x, y, w, h)\n",
    "\n",
    "# 영상의 정보 받아오기\n",
    "ret, frame = cap.read()\n",
    "\n",
    "if not ret:\n",
    "    print('frame read failed!')\n",
    "    sys.exit\n",
    "    \n",
    "roi = frame[y:y+h, x:x+w]\n",
    "roi_hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HS 히스토그램 계산\n",
    "channels = [0,1] # H와 S만 이용. V는 안씀\n",
    "ranges = [0, 180, 0, 256]\n",
    "hist = cv2.calcHit([roi_hsv], channels, None, [90, 128], ranges)\n",
    "\n",
    "# Mean Shift 알고리즘 종료 기준\n",
    "term_crit = (cv2.TERM_CRITERIA_EPA | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "# 비디오 매 프레임 처리\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "        \n",
    "    # HS 히스토그램에 대한 역투영\n",
    "    # frame을 HSV로 변환\n",
    "    frame_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    # 히스토그램 역투영 확률 데이터 얻기\n",
    "    backproj = cv2.calcBackProject([frame_hsv], channels, hist, ranges, 1)\n",
    "    \n",
    "    # Mean Shift\n",
    "    # 역투영 확률값을 Mean shift 인자에 입력\n",
    "    _, rc = cv2.meanShift(backproj, rc, term_crit)\n",
    "    \n",
    "    # 추적 결과 화면 출력\n",
    "    cv2.rectangle(frame, re, (0, 0, 255), 2)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(60) == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
